%!TEX root = disclosure_game.tex
%Rewrite all of this, ditch the alcohol stuff altogether. Any really key can be woven in elsewhere (discussion)
\section{Previous Research}

\label{sec:lit_review}

This section presents a brief overview of previous research, addressing in turn signalling games, normative decision theory, heuristic decision making, and descriptive decision theory.


\subsection{Signalling Games}

The preponderance of classical game theory focuses on strategic decision making, in scenarios where all players have complete information about all aspects of the game. An alternative, perhaps more common situation, is that players have incomplete information, i.e. their knowledge of the rules of play is in some way deficient. \citet{Harsanyi1967} introduced the concept of a Bayesian game, resolving the problems introduced by the incomplete information scenario by allowing the possible variations on the rules to be treated as subgames. This adds an additional player - nature, to the game, where nature takes the first move thereby deciding which subgame is played. Nature is assumed to make their move by lottery, and where the probability distribution governing the lottery is known to all players this permits the game to be formulated as one of complete information. Here, we are specifically interested in signalling games \citep{Kreps1987,Spence1973}, where one player holds some private information which may be communicated (or not) by means of a signal.

This basic form has been widely applied, with substantial interest in what conditions permit honest signalling as Nash equilibria or \ac{ESS}. \citet{Grafen1990}, following from a suggestion by \citet{Zahavi1975}, proposed that if signals intended to indicate mate quality exacted a cost on the signaller (e.g. peacock tail feathers), then honest signalling would constitute an \ac{ESS}. Similar results have also been demonstrated in a game of job market signalling, where signal cost was differentiated by type \citep{Spence1973}. 
Costly signalling has also been suggested as an explaination of behaviour that at first gasp appears counter intuitive, for example \citet{Godfray1991} applied the idea to the food solicitation behaviour of chicks, where a stronger signal carries a risk of being eaten. Moving beyond animal behaviour, \citet{Sosis2003} considered the implications if ritual behaviour, in the context of religion, represented a costly signal, an idea subsequently extended by \citet{Henrich2009} to include cultural transmission, and \citet{Wildman2011} to introduce group differentiation.

Other work augments the signalling game model, for example \citet{Austen-Smith2005} adds a second `peer group' audience signalling game to the original \citeauthor{Spence1973} game in an effort to explain poor academic performance in some social groups, with some subseqent empirical support for the idea from \citet{Jr2010}. On a similar tack, \citet{Feltovich2002} introduced additional noisy type information, finding that this effectively explained counterintuitive observed behaviour where actors with every right to boast of their quality faail to do so.

\subsection{Normative Decision Theory}

Where game theory addresses strategic decision making, decision theory deals instead with rational decision making \citep{Peterson2009}.  Taken literally, this leads to normative decision theory, where the focus is on giving the rational answer to a decision problem. An alternative view - descriptive, or behavioural decisin theory, holds that the focus should instead be on giving an account of human decision making, complete with observed deviations from perfect rationality, which we address in section \ref{sub:descriptive_theories}. Finally a third perspective, which to some extent overlaps this division, suggests that decisions are heuristic in nature and rational in ecological context (section \ref{sub:heuristic_theories}).

The conceptual underpinning of all of these is the central idea of expected utility, originated by \citet{Bernoulli1954} and later formalised by \citet{Neumann1953}, which treats all decisions as gambles defined in terms of payoffs and probabilities.

Recently, several studies have explored biological correlates to aspects of expected utility. The fundamental concept, that all outcomes are comparable in a universal currency has been supported by evidence of neural correlates of decision variables \citep{Platt1999}, and following from this results from \citet{Padoa-Schioppa2006,Padoa-Schioppa2008} showing neuronal firing in the \ac{OFC} corresponding to revealed preferences in monkeys. Additionally, some support for neural representation of value, and risk aversion was found by \citet{Christopoulos2009}. The model presented in this paper makes an explicit assumption that social decisions utilise the same process, and while this is less well supported there is some evidence to suggest involvement by the same brain region, since damage to the \ac{OFC} has been shown to impair social judgements in both primates \citep{Watson2012}, and humans \citep{Willis2010}.

An alternative normative model of decision making is Bayesian decision theory, proposed by \citet{Robbins1964}, which is essentially the application of Bayesian style probabilities to the expected utility model. This allows probabilities used in reasoning to be subjective, which may allow for a better account of decisions from experience (see \citet{Hau2008,Hertwig2004} for results elucidating the distinction, and comparing the performance of several non-Bayesian models). This model has seen notable successes in practical problems \citep{McNamara1980,Survey2003,Kristensen1997}, but suggestions by several authors  that it could constitute an effective (top-down) model of learning \citep{Tenenbaum2006,Griffiths2010}, or induction \citep{Gallistel2012} in the brain have attracted substantil criticism, e.g. \citet{Bowers2012}, and \citet{Miller2012} responding to \citeauthor{Tenenbaum2006,Griffiths2010}, and \citeauthor{Gallistel2012} respectively.

\subsection{Heuristic Decision Making}\label{sub:heuristic_theories}

As noted, heuristic decision making stems from a contention that \citeauthor{Neumann1953} type rationality ignores the both context of decision making, and a lack of correspondence between predicted and actual human decisions (see, for example the Allais paradox \citep{Society2013}, and subsequent empirical support \citep{Oliver2003,Burke1996}). Arguably, this begins with \citet{Simon1956}, who suggested that humans do not attempt to make optimal choices, but to satisfice and choose the first `good enough' option. While noting that this will often achieve the same result, the claim is that humans exhibit bounded rationality \citep{Simon2000} arising from inherent limits to cognition.

\citet{Gigerenzer1996} take the concept of bounded rationality further, and argue for what they term \ac{FFH}. This recasts rationality as bound to the context of the behaviour - a rational approach to choosing the right mate might well require checking every possible partner, but given finite time, memory, and so on rapidly becomes nonsensical. On this basis, they contend that the rationality of any given decision rule can only be determined in the context of the environment, which implies that heuristics are task specific. 

\subsection{Descriptive Decision Theory}\label{sub:descriptive_theories}

While heuristic theories arguably fall under the purview of the descriptive, the wider tendency is towards what are in essence patches to normative models. The most influential models in this class derive from \ac{PT} \citep{Kahneman1979}, which combines a set of heuristics based on observed decision behaviour \citep{Tversky1974}, with distortions to the perception of probability, and the value of outcomes \citep{Kahneman1984,Tversky1986} . \citet{Tversky1992} subsequently addressed issues present in their original formulation by introducing \ac{CPT}, which allows for non-binary decisions, at the expense of the heuristics. The essence then, is that high and low probabilities are treated differently, and the subjective value of a loss differs from the equivalent gain (losing your shirt is perceived as more of a loss than winning a shirt is a gain).
This last, known as the framing effect is particularly significant, see for example work by \citet{Toll2007} examining the relationship between loss and gain framings and success rates in giving up smoking, and \ac{NICE} guidance on framing of treatment options \citep{NICE2007}.

\ac{CPT} has been successful in explaining a number of anomalous results in decision tasks (see \citet{Camerer2004a} for a review), and \citet{Thaler2000} comments to the effect that the theory is promising, albeit incomplete, lacking for example any explanation of how frames are constructed. While an effective account of decision behaviour under risk, the theory does not attempt to resolve apparent inconsistencies that arise when outcomes are delayed, i.e. in situations of intertemporal choice. Historically, \ac{DU} \citep{Samuelson1937}, which effectively claims that the value of a thing now is exponentially greater than the promise of the same thing at some future date, has been applied to explain this. More recently, \citet{Ainslie1991} has suggested that discounting of future outcomes is hyperbolic, rather than exponential, although neither model is complete - both fail to account for results from \citet{Thaler1981} showing differing temporal discounting rates for losses and gains. \citet{Loewenstein1992} report additional failings in classic \ac{DU} models, and propose a modified form of \ac{CPT} which they suggest is able to handle both immediate, and intertemporal choice.


\begin{comment}Under this model, the expected utility of any gamble is a function
of the probability of the outcomes, their utility to the gambler,
and the gambler's risk aversion. Essentially this is an extension
of the expected value criterion, which assumes that the expected value
is based only on the probability and objective value of outcomes.
By contrast, the utility framing is a subjective measure, allowing
differing preferences between gamblers. \citet{Neumann1953} later
formalised the theory, defining rational decision as acting to maximise
expected utility, where an individual's preferences are shown to fulfil
four axioms, namely completeness, transitivity, independence, and
continuity. Completeness requires that for any two lotteries A and
B, the decision maker prefers one to the other, or is indifferent.
Transitivity requires that if A is preferred to B, and B is preferred
to C, then A is also preferred to C. Continuity states that given
a scenario as in the transitivity axiom, there is some combination
of lotteries A and C where the decision maker is indifferent between
that combined lottery and B. Finally, independence maintains that
if one were to prefer gamble A to B, that preference holds if both
are combined with lottery C.

Bayesian decision theory, as expounded by \citet{Robbins1964} applies
Bayesian inference to the process of decision making under some degree
of uncertainty, where decisions may be one-shot, or repeated.
The central idea is relatively straightforward, and assumes that the
loss or gain of some action to resolve a decision is contingent on
an unknown parameter. To solve the problem, the decision maker chooses
whichever action will minimise the risk, where the risk of an action
is $\underset{i}{\sum}\lambda(a_{j}|w_{i})P(w_{i}|x)$, i.e. the loss
incurred for taking action $a_{j}$ given that the true state of the
world is $w_{i}$, multiplied by the belief that this is the true
state of world given evidence $x$, summed across all possible worlds.
Essentially this is identical with expected value, with Bayesian style
probabilities. This allows an additional process of inference to progressively
update the distribution from which $P(w_{i}|x)$ derives, as new evidence
is obtained after each decision. 

This approach has been used in a wide variety of scenarios, for example
\citet{McNamara1980} have applied statistical decision theory as
a framework for understanding animal learning%
\footnote{Although they note that this is in the sense of how animals `should'
learn, rather than how they do learn%
}, while \citet{Harsanyi1978} has derived an ethical framework from
the principles. Less controversially, in contexts where optimality
is desirable as an outcome, \citet{Survey2003} have used Bayesian
decision methods in combination with \ac{MCMC} to solve complex waterfowl
habitat management problems, and \citet{Kristensen1997} has developed
robots which utilise Bayesian decision analysis to plan sensor operations.

As with standard expected utility, the Bayesian approach can be criticised,
in this case on the grounds of plausibility. The question of plausibility
arises from the suggestion that Bayesian inference is in some way
a model of human inductive reasoning, as argued by some branches of
cognitive science. For example, \citeauthor{Tenenbaum2006} argue
for the Bayesian approach as a top-down model of inductive reasoning
in humans \citep{Tenenbaum2006,Griffiths2010}, a general approach
criticised by \citet{Bowers2012} as unfalsifiable, overcomplicated,
and relying on an unrealistic conceptualisation of the brain as optimal.
\citet{Miller2012} also applied similar criticism to claims by \citet{Gallistel2012}
that Bayesian inference better characterises learning as opposed to
associative conditioning type models, suggesting that this relies
on an assumption of optimality which is unfounded.


\subsubsection{Descriptive Decision Theory}

Arguably the most significant criticism of theories of decision making,
is their failure to correspond to empirically observed decision making
\footnote{This critique is not unique to decision theory, and has also been
levelled at game theory (e.g. \citet{Fehr2003} on the irrational
altruism of humans playing the prisoners' dilemma).%
}. This was probably first raised by \citet{Simon1956}, who proposed that the
apparent divergence derived from a tendency to satisfice, rather than
optimise. This suggestion rests on the not unreasonable assumption
that people do not have unlimited cognitive capacity (i.e. bounded
rationality \citep{Simon2000}), and hence use heuristic means to
make decisions, namely by choosing the first `good enough' option.
\citeauthor{Simon1956} suggests that this process nevertheless leads
to the optimal solution is most cases.

Subsequent work on descriptive theories largely follows the same framework
in assuming that in reality, human decision making is a heuristic
process. \citet{Tversky1974} developed three heuristics to explain
observed systematic errors in reasoning - representativeness, availability,
and anchoring. Representativeness suggests that when asked to judge
how related one object or event is to another, they do this based
on the extent to which they resemble one another - crucially they
will ignore additional, better information when available. Availability
claims that when tasked with estimating probabilities, people will
rely on the ease with which they can call examples to mind (note that
this might be considered an example of satisficing). Finally, anchoring
proposes that when estimating, people start with some initial value
and progressively update from there, i.e. they will tend to overweight
prior evidence at the expense of new information. 

Subsequently, \citet{Kahneman1984,Tversky1986} also identified framing
effects, which imply that the decisions people make are impacted by
the fashion in which the problem is presented. The essential outcome
from these findings is that people are risk seeking when faced with
outcomes framed as losses, but risk averse towards gains, and regard
any loss as greater than an equivalent gain. The impact of framing
in itself has been shown to be significant, for example \citet{Toll2007}
found improved abstinence rates in smoking cessation where quitting
was framed as a gain, and \ac{NICE} recommend considering the framing
of treatment outcomes when presenting options to patients \citep{NICE2007}.

\ac{PT} \citep{Kahneman1979} attempts to provide a decision rule
accounting for the heuristic nature of decision making and incorporate
framing effects, which successfully explains many perceived failures
of rationality. A revised version, \ac{CPT} \citep{Tversky1992}
addressing a violation of first order stochastic dominance possible
under the original formulation, extends the theory to allow decisions
with more than two options, but sacrifices the editing phase. \citet{Camerer2004a}
reviews a number of successes in explaining apparent anomalies with
\ac{CPT}, and argues that should replace expected utility in general
usage. \citet{Thaler2000} regards the theory as promising, but points
out that it is in many ways incomplete, citing the lack of explanation
as to how people construct frames as an example of this.

A significant weakness of \ac{CPT} as a general theory of decision
making is that it fails to account for behaviour under intertemporal
choice, or rather does not attempt to address it. Generally, intertemporal
choice is assumed to be underpinned by the \ac{DU} model of \citet{Samuelson1937},
which proposes that the value of a thing right now is greater than
the value of it at some point in the future (jam today has more utility
than jam tomorrow), following an exponential relationship. A more
nuanced view of this has been proposed by \citet{Ainslie1991}, suggesting
that the relationship is hyperbolic rather than exponential. Both
models however fail to explain several inconsistencies, for example
\citet{Thaler1981} found that discounting rates were different between
gains and losses. \citet{Loewenstein1992} report a number of additional
inconsistencies that are not adequately resolved by \ac{DU} models,
and propose an alternative along the lines of \ac{CPT} to resolve
them while retaining the capabilities of Kahneman and Tversky's model
in immediate term choices.
\end{comment}