%!TEX root = disclosure_game.tex
%Rewrite all of this, ditch the alcohol stuff altogether. Any really key can be woven in elsewhere (discussion)
\section{Background}

\label{sec:lit_review}

This section presents a brief overview of literature focusing on the theoretical underpinning of the modelling
approach, with particular reference to statistical decision theory.


\subsection{Games, Signals, and Decisions}
\label{sub:games_signals}




\subsubsection{Signalling Games}



Game theory generally deals with strategic decision making in the
unusual circumstance of complete information, that is, every player
has at least complete knowledge of all possible outcomes, who their
opponents are, and so forth. Arguably more generally applicable is
the incomplete information scenario, where players lack information
about the rules of play in some fashion. \citet{Harsanyi1967} proposed
a method for effectively transforming such games into games of complete
information by treating the possible variations on the rules as subgames.
To determine which subgame is to be played, an additional player -
nature - is introduced to make the first move, where nature conducts
a lottery according to some probability distribution. If it is assumed
that the underlying probability distribution is known to all players,
the game is then one of complete information. 

Perhaps the best known example of Bayesian games, are the signalling
games codified by \citet{Kreps1987}, after initially being framed
by \citet{Spence1973} in the context of employment markets. The general
form of such a game is that one player holds information known only
to them, on the basis of which they send a signal to the other player(s),
which the other player(s) then act upon. Much of the interest in signalling
games turns on what conditions are necessary for honest signalling
to be a Nash equilibrium, or in the context of evolutionary game theory,
an \ac{ESS} . 

One approach to this requires that signalling is a costly exercise,
as proposed by \citet{Grafen1990} in examining biological signals
(for example, the eye-catching but unwieldy peacock tail). \citeauthor{Grafen1990}
demonstrated that an earlier suggestion by \citet{Zahavi1975}, who
proposed that such signals were in effect a handicap demonstrating
fitness, would lead to an \ac{ESS} because of the costly nature of
the signalling. This solution is also noted by \citet{Spence1973},
who showed that a separating equilibrium exists%
\footnote{In fact, an infinite number of them.%
} contingent on signals being more costly for some types.

Costly signalling has been applied to explain a variety of apparently
contradictory behaviours, for example \citet{Godfray1991} in the
context of offspring soliciting food from parents, where the key question
is why a behaviour with potentially very high costs (namely, being
eaten) would be preferred to a less risky method. In a social context,
costly signalling has been proposed as an explanation for religion
in human societies. \citet{Sosis2003} developed a model of religious
ritual as an exercise in costly signalling, showing that higher costs
to engagement in rituals for skeptics maintains the stability of religious
groups and the presumed benefits that membership confers. \citet{Henrich2009}
extended this idea, and developed an evolutionary model combining
cultural transmission with costly signalling in a population, finding
that for even modest costs the system moved towards universal belief.
\citet{Wildman2011} subsequently extended the model, to address the
fact that both stable equilibria are binary states, finding that the
incorporation of group differentiation allowed subgroups to persist.

Signalling games have also been extended to provide models of other
observed human behaviour, for example \citet{Austen-Smith2005} attempted
to explain the observed poor academic attainment of some social groups
by positing a multiple audience signalling game. They found that the
introduction of a secondary signalling game with a peer audience,
alongside the prototypical \citeauthor{Spence1973} model introduced
a pooling equilibrium. Subsequent empirical work by \citet{Jr2010}
has provided some support for this idea. Along similar lines, \citet{Feltovich2002}
examine an observed failure by high quality types to signal as would
be anticipated, introducing the concept of countersignaling in scenarios
where there is noisy leakage of type information. They found that
where there is added noisy type information available, separating
equilibriums exist where high quality senders signal either as low
quality, or not at all.


\subsubsection{Bayesian Decision Theory and Expected Utility}

Decision theory is the theory of rational decision making \citep{Peterson2009},
this contrasts with game theory which is concerned with strategic
decision making. In the broadest sense, the field can be divided into
two types of theories: normative, and descriptive. Normative theories
are those which attempt to give the rational answer to a decision
problem, descriptive or behavioural theories focus instead on characterising
the process of human decision making. In this instance, the particular
concern is with theories of decision making under uncertainty.

Underpinning almost all theories of decision making, and much of economic
theory in general is the concept of expected utility, originally proposed
by \citet{Bernoulli1954}. This casts decisions as choices between
lotteries or gambles, with differing payoffs and probabilities.

Under this model, the expected utility of any gamble is a function
of the probability of the outcomes, their utility to the gambler,
and the gambler's risk aversion. Essentially this is an extension
of the expected value criterion, which assumes that the expected value
is based only on the probability and objective value of outcomes.
By contrast, the utility framing is a subjective measure, allowing
differing preferences between gamblers. \citet{Neumann1953} later
formalised the theory, defining rational decision as acting to maximise
expected utility, where an individual's preferences are shown to fulfil
four axioms, namely completeness, transitivity, independence, and
continuity. Completeness requires that for any two lotteries A and
B, the decision maker prefers one to the other, or is indifferent.
Transitivity requires that if A is preferred to B, and B is preferred
to C, then A is also preferred to C. Continuity states that given
a scenario as in the transitivity axiom, there is some combination
of lotteries A and C where the decision maker is indifferent between
that combined lottery and B. Finally, independence maintains that
if one were to prefer gamble A to B, that preference holds if both
are combined with lottery C.

While vastly influential, the expected utility theory has been substantially
criticised, generally for failing to predict real behaviour. \citet{Society2013}
attacked the independence axiom in particular, suggesting that in
some scenarios people's choices would be inconsistent where expected
utility implies otherwise. A number of studies (e.g. \citep{Oliver2003,Burke1996})
have since supported the intuition to some extent.

More recently, support for some aspects of the expected utility theory,
particularly the concept of utility as a common currency for comparison,
has come from neurology, for example following work by \citet{Platt1999},
\citet{Padoa-Schioppa2006,Padoa-Schioppa2008} report neuronal firing
corresponding to economic value in decision making tasks undertaken
by monkeys, while \citet{Christopoulos2009} found similarly indicative
results for risk aversion. The suggestion implicit in the model proposed
here, that this also applies to social judgements, is less investigated,
although both \citet{Watson2012}, and \citet{Willis2010} found that
lesions in the brain area%
\footnote{The orbitofrontal cortex.%
} identified by \citeauthor{Padoa-Schioppa2006} lead to abnormal social
judgements in humans and primates.

Bayesian decision theory, as expounded by \citet{Robbins1964} applies
Bayesian inference to the process of decision making under some degree
of uncertainty, where decisions may be one-shot, or repeated.
The central idea is relatively straightforward, and assumes that the
loss or gain of some action to resolve a decision is contingent on
an unknown parameter. To solve the problem, the decision maker chooses
whichever action will minimise the risk, where the risk of an action
is $\underset{i}{\sum}\lambda(a_{j}|w_{i})P(w_{i}|x)$, i.e. the loss
incurred for taking action $a_{j}$ given that the true state of the
world is $w_{i}$, multiplied by the belief that this is the true
state of world given evidence $x$, summed across all possible worlds.
Essentially this is identical with expected value, with Bayesian style
probabilities. This allows an additional process of inference to progressively
update the distribution from which $P(w_{i}|x)$ derives, as new evidence
is obtained after each decision. 

This approach has been used in a wide variety of scenarios, for example
\citet{McNamara1980} have applied statistical decision theory as
a framework for understanding animal learning%
\footnote{Although they note that this is in the sense of how animals `should'
learn, rather than how they do learn%
}, while \citet{Harsanyi1978} has derived an ethical framework from
the principles. Less controversially, in contexts where optimality
is desirable as an outcome, \citet{Survey2003} have used Bayesian
decision methods in combination with \ac{MCMC} to solve complex waterfowl
habitat management problems, and \citet{Kristensen1997} has developed
robots which utilise Bayesian decision analysis to plan sensor operations.

As with standard expected utility, the Bayesian approach can be criticised,
in this case on the grounds of plausibility. The question of plausibility
arises from the suggestion that Bayesian inference is in some way
a model of human inductive reasoning, as argued by some branches of
cognitive science. For example, \citeauthor{Tenenbaum2006} argue
for the Bayesian approach as a top-down model of inductive reasoning
in humans \citep{Tenenbaum2006,Griffiths2010}, a general approach
criticised by \citet{Bowers2012} as unfalsifiable, overcomplicated,
and relying on an unrealistic conceptualisation of the brain as optimal.
\citet{Miller2012} also applied similar criticism to claims by \citet{Gallistel2012}
that Bayesian inference better characterises learning as opposed to
associative conditioning type models, suggesting that this relies
on an assumption of optimality which is unfounded.


\subsubsection{Descriptive Decision Theory}

Arguably the most significant criticism of theories of decision making,
is their failure to correspond to empirically observed decision making
\footnote{This critique is not unique to decision theory, and has also been
levelled at game theory (e.g. \citet{Fehr2003} on the irrational
altruism of humans playing the prisoners' dilemma).%
}. This was probably first raised by \citet{Simon1956}, who proposed that the
apparent divergence derived from a tendency to satisfice, rather than
optimise. This suggestion rests on the not unreasonable assumption
that people do not have unlimited cognitive capacity (i.e. bounded
rationality \citep{Simon2000}), and hence use heuristic means to
make decisions, namely by choosing the first `good enough' option.
\citeauthor{Simon1956} suggests that this process nevertheless leads
to the optimal solution is most cases.

Subsequent work on descriptive theories largely follows the same framework
in assuming that in reality, human decision making is a heuristic
process. \citet{Tversky1974} developed three heuristics to explain
observed systematic errors in reasoning - representativeness, availability,
and anchoring. Representativeness suggests that when asked to judge
how related one object or event is to another, they do this based
on the extent to which they resemble one another - crucially they
will ignore additional, better information when available. Availability
claims that when tasked with estimating probabilities, people will
rely on the ease with which they can call examples to mind (note that
this might be considered an example of satisficing). Finally, anchoring
proposes that when estimating, people start with some initial value
and progressively update from there, i.e. they will tend to overweight
prior evidence at the expense of new information. 

Subsequently, \citet{Kahneman1984,Tversky1986} also identified framing
effects, which imply that the decisions people make are impacted by
the fashion in which the problem is presented. The essential outcome
from these findings is that people are risk seeking when faced with
outcomes framed as losses, but risk averse towards gains, and regard
any loss as greater than an equivalent gain. The impact of framing
in itself has been shown to be significant, for example \citet{Toll2007}
found improved abstinence rates in smoking cessation where quitting
was framed as a gain, and \ac{NICE} recommend considering the framing
of treatment outcomes when presenting options to patients \citep{NICE2007}.

\ac{PT} \citep{Kahneman1979} attempts to provide a decision rule
accounting for the heuristic nature of decision making and incorporate
framing effects, which successfully explains many perceived failures
of rationality. A revised version, \ac{CPT} \citep{Tversky1992}
addressing a violation of first order stochastic dominance possible
under the original formulation, extends the theory to allow decisions
with more than two options, but sacrifices the editing phase. \citet{Camerer2004a}
reviews a number of successes in explaining apparent anomalies with
\ac{CPT}, and argues that should replace expected utility in general
usage. \citet{Thaler2000} regards the theory as promising, but points
out that it is in many ways incomplete, citing the lack of explanation
as to how people construct frames as an example of this.

A significant weakness of \ac{CPT} as a general theory of decision
making is that it fails to account for behaviour under intertemporal
choice, or rather does not attempt to address it. Generally, intertemporal
choice is assumed to be underpinned by the \ac{DU} model of \citet{Samuelson1937},
which proposes that the value of a thing right now is greater than
the value of it at some point in the future (jam today has more utility
than jam tomorrow), following an exponential relationship. A more
nuanced view of this has been proposed by \citet{Ainslie1991}, suggesting
that the relationship is hyperbolic rather than exponential. Both
models however fail to explain several inconsistencies, for example
\citet{Thaler1981} found that discounting rates were different between
gains and losses. \citet{Loewenstein1992} report a number of additional
inconsistencies that are not adequately resolved by \ac{DU} models,
and propose an alternative along the lines of \ac{CPT} to resolve
them while retaining the capabilities of Kahneman and Tversky's model
in immediate term choices.
